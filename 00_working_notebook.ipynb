{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy GPU enabled AKS cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prereqs:\n",
    "1. NVIDIA Docker installed for local testing: https://github.com/NVIDIA/nvidia-docker\n",
    "2. `az cli` installed and logged into\n",
    "3. `docker` installed and logged into"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "steps involved:\n",
    "1. test that you can take items from the queue locally\n",
    "2. test that you can take items from the queue from a locally running docker image\n",
    "3. test that you can take items from the queue from AKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import set_key, get_key, find_dotenv\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = find_dotenv(raise_error_if_not_found=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup service bus and add items to queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.servicebus import ServiceBusService, Message, Queue\n",
    "from azure.storage.blob import BlockBlobService\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb_service_namespace = \"jiatanamespace01\"\n",
    "sb_queue = \"batchscoringtest02\"\n",
    "sb_shared_access_key_name = \"RootManageSharedAccessKey\"\n",
    "sb_shared_access_key_value = \"Mlfcj0edqaNyf9TevJES6+0nnYT4KkeTHZ46L8X9nds=\"\n",
    "storage_account_name = \"jiataakstest\"\n",
    "storage_account_key = \"CCiyOLMA9fS98WKPBsvTFU2QWYZ+FlTv2GtaBRvZcM/oPdYRJlOUu7wISclFchYnT/mdOqqNUKnOQoBLv99fzw==\"\n",
    "\n",
    "set_key(env_path, \"SB_QUEUE\", sb_queue)\n",
    "set_key(env_path, \"SB_SERVICE_NAMESPACE\", sb_service_namespace)\n",
    "set_key(env_path, \"SB_SHARED_ACCESS_KEY_NAME\", sb_shared_access_key_name)\n",
    "set_key(env_path, \"SB_SHARED_ACCESS_KEY_VALUE\", sb_shared_access_key_value)\n",
    "set_key(env_path, \"STORAGE_ACCOUNT_NAME\", storage_account_name)\n",
    "set_key(env_path, \"STORAGE_ACCOUNT_KEY\", storage_account_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing add_images_to_queue.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile add_images_to_queue.py\n",
    "\n",
    "# service bus creds\n",
    "bus_service = ServiceBusService(\n",
    "    service_namespace=os.getenv(\"SB_SERVICE_NAMESPACE\"),\n",
    "    shared_access_key_name=os.getenv(\"SB_SHARED_ACCESS_KEY_NAME\"),\n",
    "    shared_access_key_value=os.getenv(\"SB_SHARED_ACCESS_KEY_VALUE\"),\n",
    ")\n",
    "\n",
    "# blob creds\n",
    "block_blob_service = BlockBlobService(\n",
    "    account_name=os.getenv(\"STORAGE_ACCOUNT_NAME\"),\n",
    "    account_key=os.getenv(\"STORAGE_ACCOUNT_KEY\"),\n",
    ")\n",
    "\n",
    "# list all images in specified blob under directory \"/input\"\n",
    "blob_iterator = block_blob_service.list_blobs(\"aks\", prefix=\"input\")\n",
    "\n",
    "# for all images found, add to queue\n",
    "for blob in blob_iterator:\n",
    "    print(\"adding {} to queue...\".format(blob.name.split(\"/\")[-1]))\n",
    "    msg = Message(blob.name.encode())\n",
    "    bus_service.send_queue_message(os.getenv(\"SB_QUEUE\"), msg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'IMAGE_REPO', 'batchscoringdl_receiver')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docker_login = \"jiata\"\n",
    "image_repo = \"batchscoringdl_receiver\"\n",
    "set_key(env_path, \"DOCKER_LOGIN\", docker_login)\n",
    "set_key(env_path, \"IMAGE_REPO\", image_repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "FROM nvidia/cuda:9.0-cudnn7-devel-ubuntu16.04\n",
    "\n",
    "RUN echo \"deb http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64 /\" > /etc/apt/sources.list.d/nvidia-ml.list\n",
    "\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends \\\n",
    "        build-essential \\\n",
    "        ca-certificates \\\n",
    "        cmake \\\n",
    "        curl \\\n",
    "        git \\\n",
    "        nginx \\\n",
    "        supervisor \\\n",
    "        wget && \\\n",
    "        rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "ENV PYTHON_VERSION=3.6\n",
    "RUN curl -o ~/miniconda.sh -O  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh  && \\\n",
    "    chmod +x ~/miniconda.sh && \\\n",
    "    ~/miniconda.sh -b -p /opt/conda && \\\n",
    "    rm ~/miniconda.sh && \\\n",
    "    /opt/conda/bin/conda create -y --name py$PYTHON_VERSION python=$PYTHON_VERSION && \\\n",
    "    /opt/conda/bin/conda clean -ya\n",
    "ENV PATH /opt/conda/envs/py$PYTHON_VERSION/bin:$PATH\n",
    "ENV LD_LIBRARY_PATH /opt/conda/envs/py$PYTHON_VERSION/lib:/usr/local/cuda/lib64/:$LD_LIBRARY_PATH\n",
    "ENV PYTHONPATH /code/:$PYTHONPATH\n",
    "\n",
    "RUN mkdir /app\n",
    "WORKDIR /app\n",
    "ADD receiver_app/process_images_from_queue.py /app\n",
    "ADD receiver_app/style_transfer.py /app\n",
    "ADD receiver_app/requirements.txt /app\n",
    "\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "CMD [\"python\", \"process_images_from_queue.py\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo docker build -t $image_repo ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo docker tag $image_repo $docker_login/$image_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo docker push $docker_login/$image_repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create AKS Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'AKS_CLUSTER', 'jiataakstest-gpu')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resource_group = \"jiataakstest\"\n",
    "aks_cluster = \"jiataakstest-gpu\"\n",
    "set_key(env_path, \"RESOURCE_GROUP\", resource_group)\n",
    "set_key(env_path, \"AKS_CLUSTER\", aks_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "receiver_json = {\n",
    "    \"apiVersion\": \"apps/v1beta1\",\n",
    "    \"kind\": \"Deployment\",\n",
    "    \"metadata\": {\n",
    "        \"name\": \"receiver\", \n",
    "        \"labels\": {\n",
    "            \"purpose\": \"receive_queue_messages\"\n",
    "        }\n",
    "    },\n",
    "    \"spec\": {\n",
    "        \"replicas\": 3,\n",
    "        \"template\": {\n",
    "            \"metadata\": {\n",
    "                \"labels\": {\n",
    "                    \"app\": \"receiver\"\n",
    "                }\n",
    "            },\n",
    "            \"spec\": {\n",
    "                \"containers\": [\n",
    "                    {\n",
    "                        \"name\": \"receiver\",\n",
    "                        \"image\": \"{}/{}:latest\".format(get_key(env_path, \"DOCKER_LOGIN\"), get_key(env_path, \"IMAGE_REPO\")),\n",
    "                        \"volumeMounts\": [\n",
    "                            {\n",
    "                                \"mountPath\": \"/usr/local/nvidia\", \n",
    "                                \"name\": \"nvidia\"\n",
    "                            }\n",
    "                        ],\n",
    "                        \"resources\": {\n",
    "                            \"requests\": {\n",
    "                                \"alpha.kubernetes.io/nvidia-gpu\": 1\n",
    "                            },\n",
    "                            \"limits\": {\n",
    "                                \"alpha.kubernetes.io/nvidia-gpu\": 1\n",
    "                            },\n",
    "                        },\n",
    "                        \"ports\": [{\n",
    "                            \"containerPort\": 433\n",
    "                        }],\n",
    "                        \"env\": [\n",
    "                            {\n",
    "                                \"name\": \"LB_LIBRARY_PATH\",\n",
    "                                \"value\": \"$LD_LIBRARY_PATH:/usr/local/nvidia/lib64:/opt/conda/envs/py3.6/lib\",\n",
    "                            },\n",
    "                            {\n",
    "                                \"name\": \"DP_DISABLE_HEALTHCHECKS\", \n",
    "                                \"value\": \"xids\"\n",
    "                            },\n",
    "                            {\n",
    "                                \"name\": \"SB_SERVICE_NAMESPACE\",\n",
    "                                \"value\": get_key(env_path, \"SB_SERVICE_NAMESPACE\")\n",
    "                            },\n",
    "                            {\n",
    "                                \"name\": \"SB_QUEUE\", \n",
    "                                \"value\": get_key(env_path, \"SB_QUEUE\")\n",
    "                            },\n",
    "                            {\n",
    "                                \"name\": \"SB_SHARED_ACCESS_KEY_NAME\",\n",
    "                                \"value\": get_key(env_path, \"SB_SHARED_ACCESS_KEY_NAME\")\n",
    "                            },\n",
    "                            {\n",
    "                                \"name\": \"SB_SHARED_ACCESS_KEY_VALUE\",\n",
    "                                \"value\": get_key(env_path, \"SB_SHARED_ACCESS_KEY_VALUE\")\n",
    "                            },\n",
    "                            {\n",
    "                                \"name\": \"STORAGE_ACCOUNT_NAME\", \n",
    "                                \"value\": get_key(env_path, \"STORAGE_ACCOUNT_NAME\")\n",
    "                            },\n",
    "                            {\n",
    "                                \"name\": \"STORAGE_ACCOUNT_KEY\",\n",
    "                                \"value\": get_key(env_path, \"STORAGE_ACCOUNT_KEY\")\n",
    "                            },\n",
    "                        ],\n",
    "                    }\n",
    "                ],\n",
    "                \"volumes\": [\n",
    "                    {\n",
    "                        \"name\": \"nvidia\", \n",
    "                        \"hostPath\": {\n",
    "                            \"path\": \"/usr/local/nvidia\"\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"receiver.json\", \"w\") as outfile:\n",
    "    json.dump(receiver_json, outfile, indent=4, sort_keys=True)\n",
    "    outfile.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/receiver created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl create -f receiver.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                          READY   STATUS              RESTARTS   AGE\r\n",
      "receiver-77dd86c478-6kqhn     0/1     ContainerCreating   0          2s\r\n",
      "receiver-77dd86c478-skd4v     0/1     ContainerCreating   0          2s\r\n",
      "receiver-77dd86c478-vlzfs     0/1     ContainerCreating   0          2s\r\n",
      "samples-tf-mnist-demo-6p4bv   0/1     Pending             0          3h26m\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `az aks browse -n $aks_cluster -g $resource_group` in your terminal so that you can use the Kubernetes Dashboard. If you're not able to access the dashboard, follow the instructions here: https://blog.tekspace.io/kubernetes-dashboard-remote-access/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:batchscoringdl_v2]",
   "language": "python",
   "name": "conda-env-batchscoringdl_v2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
